{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "train_path = \"/Users/Conlin/Desktop/Hackthon/data/train.csv\"\n",
    "test_path = \"/Users/Conlin/Desktop/Hackthon/data/test.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "combine = [train_df, test_df]\n",
    "train_df.dropna(inplace = True)\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df\n",
    "# train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.smoker_status[train_data.smoker_status == 'non-smoker'] = 0\n",
    "# train_data.smoker_status[train_data.smoker_status == 'quit'] = 1\n",
    "# train_data.smoker_status[train_data.smoker_status == 'active_smoker'] = 2\n",
    "# train_df.dropna(inplace = True) \n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False \n",
    "\n",
    "def rep_unum(column):\n",
    "    for i in column:\n",
    "        if str(i).isdigit() or str(i).isnumeric():\n",
    "            pass\n",
    "        elif i == \"nan\" or i ==\".\":\n",
    "            i = 0\n",
    "        else:\n",
    "            i = 0\n",
    "    \n",
    "for dataset in combine:\n",
    "    dataset.dropna(inplace = True)\n",
    "    dataset['smoker_status'] = dataset['smoker_status'].map({'non-smoker': 1, 'quit': 2, 'active_smoker': 3})\n",
    "#     # new data frame with split value columns \n",
    "#     new = dataset[\"sex and age\"].str.split(\",\", n = 1, expand = True) \n",
    "#     # making separate first name column from new data frame \n",
    "#     dataset[\"sex\"]= new[0] \n",
    "#     # making separate last name column from new data frame \n",
    "#     dataset[\"age\"]= new[1] \n",
    "#     # Dropping old Name columns \n",
    "#     dataset.drop(columns =[\"sex and age\"], inplace = True) \n",
    "    dataset[\"sex and age\"].fillna(\"-1,-1\",inplace = True)\n",
    "    dataset.replace('None','-1')\n",
    "\n",
    "    dataset[[\"sex\",\"age\"]] = dataset[\"sex and age\"].str.split(\",\",expand = True)\n",
    "    sex = dataset.sex\n",
    "    age = dataset.age\n",
    "\n",
    "    sex1 = sex.tolist()\n",
    "    sex2 = sex.tolist()\n",
    "    age1 = age.tolist()\n",
    "\n",
    "    for i in range(len(sex1)):\n",
    "        if sex1[i] == 'M' or sex1[i] == 'F' or sex1[i] == '-1' or sex1[i] == 'Male' or sex1[i] == 'Female':\n",
    "            pass\n",
    "        else:\n",
    "            sex1[i] = age1[i]\n",
    "            sex1[i]=sex1[i].strip(\" \")\n",
    "    for i in range(len(age1)):\n",
    "        age1[i] = age1[i].strip(\" \")\n",
    "        if age1[i] == 'M' or age1[i] == 'F' or age1[i] == 'Male' or age1[i] == 'Female':\n",
    "            age1[i] = sex2[i]\n",
    "\n",
    "    for i in range(len(age1)):\n",
    "        if not is_number(age1[i]):\n",
    "            age1[i] = '0'\n",
    "        \n",
    "    dataset.sex = sex1\n",
    "    dataset.age = age1\n",
    "    \n",
    "    dataset.drop(columns =[\"sex and age\"], inplace = True)\n",
    "    \n",
    "    dataset[[\"job_status\",\"living_area\"]] = train_df[\"job_status and living_area\"].str.split(\"?\",expand = True)\n",
    "\n",
    "    job_status = dataset.job_status\n",
    "    living_area = dataset.living_area\n",
    "\n",
    "    job_status1 = job_status.tolist()\n",
    "    living_area1 = living_area.tolist()\n",
    "    living_area2 = living_area.tolist()\n",
    "\n",
    "    for i in range(len(living_area1)):\n",
    "        if living_area1[i] == 'Remote' or living_area1[i] =='City' or living_area1[i] == 'remote' or living_area1[i] == 'cIty' or living_area1[i] == 'remotee' or living_area1[i] =='city' or living_area1[i] == 'CITY' or living_area1[i] == 'c' or living_area1[i] == 'r'or living_area1[i] == 'CIty' or living_area1[i] == '-1 ':\n",
    "            pass\n",
    "        else:\n",
    "            living_area1[i] = job_status1[i]\n",
    "\n",
    "    for i in range(len(job_status1)):\n",
    "        if job_status1[i] == 'Remote' or job_status1[i] =='City' or job_status1[i] == 'remote' or job_status1[i] == 'cIty' or job_status1[i] == 'remotee' or job_status1[i] =='city' or job_status1[i] == 'CITY' or job_status1[i] == 'c' or job_status1[i] == 'r'or job_status1[i] == 'CIty' or job_status1[i] == '-1 ':\n",
    "            job_status1[i] = living_area2[i]\n",
    "\n",
    "    dataset.job_status = job_status1\n",
    "    dataset.living_area = living_area1\n",
    "    \n",
    "#     dataset.fillna(\"-1\",inplace = True)\n",
    "    \n",
    "    dataset['sex'] = dataset['sex'].map({'M': 1, 'F': 2})\n",
    "    \n",
    "    dataset['job_status'] = dataset['job_status'].map({'government': 1, 'private_sector': 2,'business_owner':3})\n",
    "    \n",
    "    dataset[\"living_area\"] = dataset[\"living_area\"].map({'Remote': 1, 'City': 2})\n",
    "    \n",
    "    for i in dataset.columns:\n",
    "        rep_unum(dataset[i]) \n",
    "    \n",
    "#     TD = dataset.TreatmentD\n",
    "    \n",
    "#     TD_l = TD.tolist()\n",
    "    \n",
    "#     for i in range(len(TD_l)):\n",
    "#         if TD_l[i] == '0+E1860:E1868':\n",
    "#             TD_l[i] = '0'\n",
    "#     for i in TD_l:\n",
    "#         if i == '0+E1860:E1868':\n",
    "#             print(i)\n",
    "    \n",
    "#     dataset.TreatmentD = TD_l\n",
    "\n",
    "\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# for i in var_mod:\n",
    "#     train[stroke_in_2018] = le.fit_transform(df[i].astype(int))\n",
    "    \n",
    "\n",
    "    \n",
    "#     dataset.replace(['other', 'Other'], [-1,-1]) \n",
    "    \n",
    "\n",
    "train_df.drop(columns =[\"job_status and living_area\"], inplace = True)  \n",
    "test_df.drop(columns =[\"job_status and living_area\"], inplace = True)\n",
    "train_df.drop(train_df.index[train_df.stroke_in_2018 == 'a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_df.columns:\n",
    "#     print(pd.unique(train_df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "len(train_df.columns)\n",
    "len(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id   [23999 40190 18675 ... 10179 22310 11343]\n",
      "high_BP   ['0' '1']\n",
      "heart_condition_detected_2017   ['1']\n",
      "married   ['1' '0']\n",
      "average_blood_sugar   [200.96 262.62  84.21 ...  76.72 114.36  80.58]\n",
      "BMI   ['31.3' '34.1' '29.6' '42.3' '37.6' '34.5' '31.7' '35.1' '33.8' '41.5'\n",
      " '28.8' '36.3' '47.1' '32.1' '32.5' '29.9' '28.3' '41.4' '25' '46.4'\n",
      " '35.7' '31.9' '33.7' '29.7' '28.1' '30.9' '35.2' '24.1' '30.2' '25.6'\n",
      " '32.8' '37.8' '26.5' '27.5' '33.5' '35.8' '29.3' '33' '38.1' '30.8'\n",
      " '30.1' '29.2' '27.8' '39.3' '37.1' '42.6' '30.7' '38.8' '33.1' '57'\n",
      " '36.8' '26.6' '30.3' '27.6' '27.3' '35.6' '37.3' '27.7' '27.9' '32.2'\n",
      " '40.8' '27.2' '29.1' '29.5' '39.1' '26.1' '34.2' '28.7' '28.2' '46'\n",
      " '24.2' '31.4' '37.5' '29.8' '39' '33.4' '30' '28.9' '40.3' '39.4' '54'\n",
      " '35.5' '39.2' '40.2' '35.9' '33.6' '32.4' '23' '41.3' '24.6' '36.9'\n",
      " '34.9' '45.3' '31.2' '28.6' '30.4' '42.5' '23.1' '30.6' '41' '22.7'\n",
      " '26.4' '55.5' '25.4' '28.5' '45' '45.5' '34.8' '25.9' '25.7' '26.3'\n",
      " '36.5' '45.2' '43' '43.4' '38.6' '27.4' '29.4' '28' '23.2' '34.6' '32'\n",
      " '44.2' '42.2' '32.9' '27.1' '24.5' '36.2' '24.8' '40.4' '36' '46.3'\n",
      " '28.4' '22.5' '42' '45.6' '33.9' '42.4' '31.6' '61.6' '40.6' '23.3' '27'\n",
      " '32.3' '38.2' '32.6' '33.2' '25.5' '32.7' '31.8' '31.5' '34.4' '39.7'\n",
      " '23.8' '34.7' '24.9' '20.1' '44.6' '26.8' '21.3' '35' '39.5' '38.4'\n",
      " '44.8' '40.9' '34.3' '37.7' '41.2' '25.8' '21.2' '25.1' '23.5' '33.3'\n",
      " '43.7' '44.7' '23.7' '20.3' '38.3' '42.7' '19.1' '22.8' '40.1' '37.9'\n",
      " '39.9' '21.5' '41.6' '36.7' '26.7' '29' '26.2' '62.6' '31' '43.1' '37'\n",
      " '36.1' '30.5' '24' '46.9' '35.3' '38.7' '24.7' '49.6' '51.5' '60.9'\n",
      " '39.8' '44.3' '48.3' '49.2' '23.4' '38.5' '42.8' '25.3' '23.9' '25.2'\n",
      " '31.1' '23.6' '45.4' '22.4' '40.5' '21.4' '41.7' '43.3' '41.8' '20.7'\n",
      " '36.6' '59.6' '38' '44.1' '43.2' '44.9' '35.4' '41.9' '16.6' '47.6'\n",
      " '56.7' '24.3' '46.8' '34' '54.2' '40' '38.9' '47.9' '44' '19.5' '47'\n",
      " '46.7' '37.4' '45.7' '24.4' '44.5' '51.9' '42.1' '57.9' '51.7' '37.2'\n",
      " '21.8' '21.1' '36.4' '45.8' '39.6' '42.9' '22.9' '53.1' '47.4' '43.5'\n",
      " '18.4' '50.2' '52.3' '22.1' '26' '49.9' '21.6' '46.2' '48.5' '22.3'\n",
      " '56.9' '43.6' '26.9' '22.2' '43.8' '51' '48']\n",
      "smoker_status   [ 2.  3.  1. nan]\n",
      "TreatmentA   [0. 1.]\n",
      "TreatmentB   [0. 1.]\n",
      "TreatmentC   [0. 1.]\n",
      "TreatmentD   ['0' '1']\n",
      "stroke_in_2018   ['0' '1' '.']\n",
      "sex   [1 2]\n",
      "age   ['79' '69' '76' '72' '66' '82' '39' '73' '74' '67' '85' '52' '80' '84'\n",
      " '83' '71' '55' '59' '75' '56' '70' '51' '63' '65' '60' '54' '47' '64'\n",
      " '81' '49' '62' '46' '78' '44' '58' '40' '61' '53' '68' '57' '77' '48'\n",
      " '50' '37' '41' '45' '34' '36' '42' '32' '38' '31' '43']\n",
      "job_status   [ 3.  2.  1. nan]\n",
      "living_area   [2 1]\n"
     ]
    }
   ],
   "source": [
    "for i in train_df.columns:\n",
    "    print(i,\" \",pd.unique(train_df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1212, 15), (1212,), (305, 14))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(\"stroke_in_2018\", axis=1)\n",
    "Y_train = train_df[\"stroke_in_2018\"]\n",
    "X_test  = test_df.drop(\"id\", axis=1).copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-4b13baedfbad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandom_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 568\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '?'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-a78f18ad61c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgaussian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgaussian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0macc_gaussian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaussian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    192\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '?'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Gaussian Naive Bayes\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, Y_train)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-2428155a2f7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m submission = pd.DataFrame({\n\u001b[1;32m      2\u001b[0m         \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m\"stroke_in_2018\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     })\n\u001b[1;32m      5\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./output/submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"id\": test_df[\"id\"],\n",
    "        \"stroke_in_2018\": Y_pred\n",
    "    })\n",
    "submission.to_csv('./output/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
